{
  "name": "supercrawler",
  "description": "A web crawler. Supercrawler automatically crawls websites. Define custom handlers to parse content. Obeys robots.txt, rate limits and concurrency limits.",
  "version": "2.3.0",
  "homepage": "https://github.com/cbess/supercrawler",
  "license": "Apache-2.0",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/cbess/supercrawler.git"
  },
  "keywords": [
    "crawler",
    "spider",
    "supercrawler"
  ],
  "scripts": {
    "test": "mocha --recursive",
    "coverage": "nyc --reporter=lcov --check-coverage npm test"
  },
  "main": "./lib/index.js",
  "devDependencies": {
    "chai": "^4.2.0",
    "mocha": "^6.1.4",
    "nyc": "^14.1.0",
    "proxyquire": "^2.1.0",
    "sinon": "^1.17.7"
  },
  "dependencies": {
    "axios": "0.21.1",
    "bluebird": "3.7.2",
    "cheerio": "1.0.0-rc.10",
    "ioredis": "4.9.3",
    "lodash": "4.17.21",
    "mime-types": "2.1.31",
    "node-cache": "4.2.0",
    "robots-parser": "2.3.0",
    "sequelize": "6.6.2",
    "sqlite3": "5.0.2"
  },
  "engines": {
    "node": ">=14"
  }
}